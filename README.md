# ðŸŽ­ Emotion Classification from Speech

This project implements an **emotion classification system** that analyzes speech and identifies the emotion conveyed. The system uses the RAVDESS dataset and a **Multi-Layer Perceptron (MLP)** model for classification.

---

## ðŸŒŸ Project Highlights

- **Feature Extraction**: Extracted MFCC, chroma, and Mel spectrogram features from audio files. ðŸŽ¶
- **Emotion Detection**: Focused on detecting emotions such as calm, happy, fearful, and disgusted. ðŸ˜ŒðŸ˜ŠðŸ˜¨ðŸ¤¢
- **MLP Classifier**: Used a neural network for classification. ðŸ¤–
- **High Accuracy**: Achieved **accuracy > 75%** for emotion classification. ðŸ“ˆ

---

ðŸ“Š **Data Overview**

Dataset: RAVDESS

Emotions Observed: calm, happy, fearful, disgust

Features Extracted:

MFCC: Mel-Frequency Cepstral Coefficients

Chroma: Chromagram features

Mel Spectrogram: Spectral analysis

ðŸ¤– **Model Details**

Model Type: Multi-Layer Perceptron (MLP)

Features Used: MFCC, chroma, Mel

Optimizer: Adam

Loss Function: Cross-Entropy Loss

Accuracy Achieved: > 75%

